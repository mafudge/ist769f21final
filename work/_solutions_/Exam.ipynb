{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddd06f7-3837-4ef9-8d70-cfe075736595",
   "metadata": {},
   "source": [
    "# IST769 Final Exam\n",
    "\n",
    "**INSTRUCTIONS FOR HIGHEST GRADE POSSIBLE**\n",
    "\n",
    "Unless you are explicitly instructed otherwise, answer each of the following using PySpark / Spark SQL. For any queries you write make sure to include a `printSchema()` and sample(s) of the output which clearly demonstrates the code is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25feebd0-d09b-4233-b9af-ec965875930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp /home/jovyan/work/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar /usr/local/spark/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4308c98a-a418-4120-9ee7-05992d21e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c73c8d6-8ab6-44a8-8a78-51598b8c07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91718b91-ceae-416d-b96c-053a5d844676",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "In the cell below configure a spark session that is configured to connect to `mongodb`, `minio`, `cassandra`, '`elasticsearch` and `neo4j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5ecf9f-0798-4bc9-8896-229a0faade48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      "org.elasticsearch#elasticsearch-spark-20_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0952c077-e0db-4835-bd67-87699622c747;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 in central\n",
      "\tfound org.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.6 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;2.4.4 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      ":: resolution report :: resolve 1389ms :: artifacts dl 63ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;2.4.4 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-20_2.12;7.15.0 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   8   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0952c077-e0db-4835-bd67-87699622c747\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 8 already retrieved (0kB/54ms)\n",
      "23/04/13 17:38:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#1 Spark session\n",
    "\n",
    "cassandra_host = \"cassandra\"\n",
    "elastic_host = \"elasticsearch\"\n",
    "elastic_port = \"9200\"\n",
    "bolt_url = \"bolt://neo4j:7687\"\n",
    "s3_host = \"minio\"\n",
    "s3_url = f\"http://{s3_host}:9000\"\n",
    "s3_key = \"minio\"\n",
    "s3_secret = \"SU2orange!\"\n",
    "s3_bucket = \"minio-example\"\n",
    "mongo_uri = \"mongodb://admin:mongopw@mongo:27017/ischooldb?authSource=admin\"\n",
    "jars = [\n",
    "    \"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\",\n",
    "    \"org.elasticsearch:elasticsearch-spark-20_2.12:7.15.0\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.1.2\"\n",
    "]\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "    .config(\"spark.es.nodes\", elastic_host) \\\n",
    "    .config(\"spark.es.port\",elastic_port) \\\n",
    "    .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "    .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_url) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.jars.packages\",\",\".join(jars))\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee055a5-7a8f-4739-a3f5-a52d981ea05e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Demonstrate you can read the process-oriented data `enrollments` and `sections` from `minio` using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50367be-c7ac-43b0-b820-54e4b7d83c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|term|course_enrollment|course|section|       student_id|grade|grade_points|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "|1221|                1|IST659|   M001|      orenjouglad|    C|         2.0|\n",
      "|1221|                2|IST659|   M001|      billmelator|    A|         4.0|\n",
      "|1221|                3|IST659|   M001|       morrisless|    A|         4.0|\n",
      "|1221|                4|IST659|   M001|amberwavesofgrain|   A-|       3.667|\n",
      "|1221|                5|IST659|   M001|         abbykuss|    A|         4.0|\n",
      "+----+-----------------+------+-------+-----------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: string (nullable = true)\n",
      " |-- course_enrollment: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2a enrollments\n",
    "enrollments = spark.read.csv(\"s3a://enrollments/enrollments.csv\",header=True)\n",
    "enrollments.show(5)\n",
    "enrollments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b415479-5acf-42dc-b535-c80bc62d239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+--------+\n",
      "|term|course|section|enrollment|capacity|\n",
      "+----+------+-------+----------+--------+\n",
      "|1221|IST659|   M001|        20|      20|\n",
      "|1221|IST659|   M002|        20|      20|\n",
      "|1221|IST722|   M001|        25|      28|\n",
      "|1221|IST615|   M001|        22|      28|\n",
      "|1221|IST621|   M001|        22|      24|\n",
      "+----+------+-------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2b sections \n",
    "sections=spark.read.csv(\"s3a://enrollments/sections.csv\",header=True)\n",
    "sections.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74906498-d775-451f-befd-5e88595b7009",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Demonstrate you can read the reference-oriented data `terms`, `students`, `courses`, and `program` reference data from `MongoDb` using PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f928bc1-1306-42d7-a073-c7673dde4f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----+-----------+--------+----+\n",
      "| _id|academic_year|code|       name|semester|year|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "|1221|    2021-2022|1221|  Fall 2021|    Fall|2021|\n",
      "|1222|    2021-2022|1222|Spring 2022|  Spring|2022|\n",
      "|1231|    2022-2023|1231|  Fall 2022|    Fall|2022|\n",
      "|1232|    2022-2023|1232|Spring 2023|  Spring|2023|\n",
      "+----+-------------+----+-----------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3a terms \n",
    "terms = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"terms\").load()\n",
    "terms.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b917eaca-2e3e-45ab-84aa-bc2f07bf6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|   _id|  code|credits|         description|elective_in_programs| key_assignments|                name|prerequisites|required_in_programs|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "|IST659|IST659|      3|Definition, devel...|                  []|       [project]|Data Administrati...|           []|            [IS, DS]|\n",
      "|IST722|IST722|      3|Introduction to c...|                [IS]| [project, exam]|    Data Warehousing|     [IST659]|                  []|\n",
      "|IST769|IST769|      3|Analyze relationa...|                [DS]| [project, exam]|Advanced Big Data...|     [IST659]|                  []|\n",
      "|IST615|IST615|      3|Cloud services cr...|                  []|[project, paper]|    Cloud Management|           []|            [IS, DS]|\n",
      "|IST714|IST714|      3|Advanced, lab-bas...|            [IS, DS]|       [project]|  Cloud Architecture|     [IST615]|                  []|\n",
      "+------+------+-------+--------------------+--------------------+----------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3b courses\n",
    "courses = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"courses\").load()\n",
    "courses.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f483a03-3da6-4efa-95d7-06c82e556400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "|_id|code|credits|    elective_courses|                name|    required_courses|       type|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "| IS|  IS|     36|[IST722, IST714, ...| Information Systems|[IST659, IST615, ...|    Masters|\n",
      "| DS|  DS|     34|    [IST769, IST714]|        Data Science|[IST659, IST615, ...|    Masters|\n",
      "|BDC| BDC|      9|                null|Data Engineering ...|[IST659, IST722, ...|Certificate|\n",
      "|CCC| CCC|      9|                null|Cloud Computing C...|[IST621, IST615, ...|Certificate|\n",
      "|MLC| MLC|      9|                null|Machine Learning ...|[IST687, IST707, ...|Certificate|\n",
      "+---+----+-------+--------------------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3c Programs\n",
    "programs = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"programs\").load()\n",
    "programs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d87294-61eb-4dd4-8b7a-5c280b6b7c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------+\n",
      "|         _id|         name|program|\n",
      "+------------+-------------+-------+\n",
      "|    abbykuss|    Abby Kuss|     DS|\n",
      "|  adamantium|  Adam Antium|     IS|\n",
      "|   addieowse|   Addie Owse|     IS|\n",
      "|aidensomewun|Aiden Somewun|     IS|\n",
      "|aidenknowone|Aiden Knowone|     DS|\n",
      "+------------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3d students\n",
    "students = spark.read.format(\"mongo\").option(\"database\",\"ischooldb\").option(\"collection\",\"students\").load()\n",
    "students.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfca28-8272-46ee-b98c-6a263be01c56",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Prepare the `section` data for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. Just PREPARE it do not LOAD it. Remember that we want this data to be as wide as possible, so include all relevant reference data. For example, the `section` data should include `term` attributes like `year`,  `academic year`, etc... and from `course`, attributes like `credits`, `name`, `prerequisites`, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e8a9218-9dc1-4e69-87d8-90274d579ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+--------+--------------+----------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+---------+-----------+-------------+---------+------------------+\n",
      "|term|course|section|enrollment|capacity|course_credits|    course_title|  course_description|course_is_elective_in_programs|course_is_required_in_programs|course_prerequisites|course_key_assignments|term_code|  term_name|term_semester|term_year|term_academic_year|\n",
      "+----+------+-------+----------+--------+--------------+----------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+---------+-----------+-------------+---------+------------------+\n",
      "|1221|IST615|   M001|        22|      28|             3|Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|     1221|  Fall 2021|         Fall|     2021|         2021-2022|\n",
      "|1222|IST615|   M001|        19|      24|             3|Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|     1222|Spring 2022|       Spring|     2022|         2021-2022|\n",
      "|1231|IST615|   M001|        21|      24|             3|Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|     1231|  Fall 2022|         Fall|     2022|         2022-2023|\n",
      "|1232|IST615|   M002|        20|      24|             3|Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|     1232|Spring 2023|       Spring|     2023|         2022-2023|\n",
      "|1232|IST615|   M001|        21|      28|             3|Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|     1232|Spring 2023|       Spring|     2023|         2022-2023|\n",
      "+----+------+-------+----------+--------+--------------+----------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+---------+-----------+-------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- enrollment: string (nullable = true)\n",
      " |-- capacity: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_title: string (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_is_elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_is_required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- term_code: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- term_academic_year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4 wide_sections\n",
    "sections.createOrReplaceTempView(\"sections\")\n",
    "terms.createOrReplaceTempView(\"terms\")\n",
    "courses.createOrReplaceTempView(\"courses\")\n",
    "query = '''\n",
    "    select \n",
    "        s.*, \n",
    "        c.credits as course_credits,\n",
    "        c.name as course_title,\n",
    "        c.description as course_description,\n",
    "        c.elective_in_programs as course_is_elective_in_programs,\n",
    "        c.required_in_programs as course_is_required_in_programs,\n",
    "        c.prerequisites as course_prerequisites,\n",
    "        c.key_assignments as course_key_assignments,\n",
    "        t.code as term_code,\n",
    "        t.name as term_name,\n",
    "        t.semester as term_semester,\n",
    "        t.year as term_year,\n",
    "        t.academic_year as term_academic_year\n",
    "    from sections s\n",
    "        join terms t on s.term = t._id\n",
    "        join courses c on s.course = c._id\n",
    "'''\n",
    "wide_sections = spark.sql(query)\n",
    "wide_sections.show(5)\n",
    "wide_sections.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f972cf-8ab1-48fe-b2ff-607acc11e05d",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Use the `cassandra-driver` example from class to write python code to connect to cassandra from within Jupyter and create a keyspace named `ischooldb`. Design a cassandra table called `sections` to store the data from question 4. Appropriate key design is important! Please explain your justification for key below your table definition. Provide clear evidence that your table was created by querying the empty table in spark and use `printSchema()` to show the schema. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4015e68d-c1d0-4bb6-962e-f42bdaeb28c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+--------+--------------+------------------+------------------------------+------------------------------+----------------------+--------------------+------------+----------+------------------+---------+---------+-------------+---------+\n",
      "|term|course|section|capacity|course_credits|course_description|course_is_elective_in_programs|course_is_required_in_programs|course_key_assignments|course_prerequisites|course_title|enrollment|term_academic_year|term_code|term_name|term_semester|term_year|\n",
      "+----+------+-------+--------+--------------+------------------+------------------------------+------------------------------+----------------------+--------------------+------------+----------+------------------+---------+---------+-------------+---------+\n",
      "+----+------+-------+--------+--------------+------------------+------------------------------+------------------------------+----------------------+--------------------+------------+----------+------------------+---------+---------+-------------+---------+\n",
      "\n",
      "root\n",
      " |-- term: string (nullable = false)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- capacity: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- course_is_elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_is_required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_title: string (nullable = true)\n",
      " |-- enrollment: string (nullable = true)\n",
      " |-- term_academic_year: string (nullable = true)\n",
      " |-- term_code: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5 create cassandra table for wide_sections\n",
    "create_table = '''\n",
    "CREATE TABLE IF NOT EXISTS ischooldb.sections (\n",
    "    term text,\n",
    "    course text,\n",
    "    section text,\n",
    "    enrollment text,\n",
    "    capacity text,\n",
    "    course_credits int,\n",
    "    course_title text,\n",
    "    course_description text,\n",
    "    course_is_elective_in_programs list<text>,\n",
    "    course_is_required_in_programs list<text>,\n",
    "    course_prerequisites list<text>,\n",
    "    course_key_assignments list<text>,\n",
    "    term_code text,\n",
    "    term_name text,\n",
    "    term_semester text,\n",
    "    term_year int,\n",
    "    term_academic_year text,\n",
    "    primary key ((term),course,section)\n",
    ");\n",
    "'''\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS ischooldb WITH replication={ 'class': 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "    session.execute(\"drop table if exists ischooldb.sections;\")\n",
    "    session.execute(create_table)\n",
    "\n",
    "df = spark.read.format(\"org.apache.spark.sql.cassandra\").option(\"table\", \"sections\").option(\"keyspace\",\"ischooldb\").load()\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71b3b5-03d7-456d-a64f-f3c5f0c93836",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Load the data frame you created in question 4 into the `cassandra` table you created in question 5. Demonstrate the data is in the table by querying back it with PySpark. Make sure you can run the code multiple times and each time it replaces the existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59e9aac0-da49-4c82-8e3f-184b5f1d9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 273:=======================================>             (150 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+--------+--------------+--------------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+----------+------------------+---------+-----------+-------------+---------+\n",
      "|term|course|section|capacity|course_credits|  course_description|course_is_elective_in_programs|course_is_required_in_programs|course_key_assignments|course_prerequisites|        course_title|enrollment|term_academic_year|term_code|  term_name|term_semester|term_year|\n",
      "+----+------+-------+--------+--------------+--------------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+----------+------------------+---------+-----------+-------------+---------+\n",
      "|1222|IST615|   M001|      24|             3|Cloud services cr...|                            []|                      [IS, DS]|      [project, paper]|                  []|    Cloud Management|        19|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "|1222|IST621|   M001|      28|             3|Information and t...|                            []|                          [IS]|               [paper]|                  []|Information Manag...|        28|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "|1222|IST621|   M002|      24|             3|Information and t...|                            []|                          [IS]|               [paper]|                  []|Information Manag...|        22|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "|1222|IST659|   M001|      24|             3|Definition, devel...|                            []|                      [IS, DS]|             [project]|                  []|Data Administrati...|        24|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "|1222|IST687|   M001|      20|             3|Introduces inform...|                          [IS]|                          [DS]|       [project, exam]|                  []|Introduction to D...|        18|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "+----+------+-------+--------+--------------+--------------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+----------+------------------+---------+-----------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#6 load wide_sections into cassandra\n",
    "wide_sections.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .option(\"table\", \"sections\")\\\n",
    "  .option(\"keyspace\",\"ischooldb\")\\\n",
    "  .save()\n",
    "\n",
    "df = spark.read.format(\"org.apache.spark.sql.cassandra\").option(\"table\", \"sections\").option(\"keyspace\",\"ischooldb\").load()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052fbcc-b7cc-4fa7-ba5d-09b3066c8b96",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Since we did not learn how to create a custom elasticsearch mapping, before you can load the data into `elasticsearch` you will need to flatten the nested data. For example, `course_is_elective_in_programs` should generate 2 columns `course_is_elective_for_IS` and `course_is_elective_for_DS`. You'll need to repeat this step for `course_is_required_in_programs`. Omit the `course_prerequisites` and `course_key_assignments` column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99f91002-2880-4f4c-8392-9b869ce42172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------+----------+--------+--------------+--------------------+--------------------+---------+-----------+-------------+---------+------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|term|course|section|enrollment|capacity|course_credits|        course_title|  course_description|term_code|  term_name|term_semester|term_year|term_academic_year|course_is_elective_in_IS|course_is_elective_in_DS|course_is_required_in_IS|course_is_required_in_DS|\n",
      "+----+------+-------+----------+--------+--------------+--------------------+--------------------+---------+-----------+-------------+---------+------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|1221|IST615|   M001|        22|      28|             3|    Cloud Management|Cloud services cr...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                   false|                   false|                    true|                    true|\n",
      "|1222|IST615|   M001|        19|      24|             3|    Cloud Management|Cloud services cr...|     1222|Spring 2022|       Spring|     2022|         2021-2022|                   false|                   false|                    true|                    true|\n",
      "|1231|IST615|   M001|        21|      24|             3|    Cloud Management|Cloud services cr...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1232|IST615|   M002|        20|      24|             3|    Cloud Management|Cloud services cr...|     1232|Spring 2023|       Spring|     2023|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1232|IST615|   M001|        21|      28|             3|    Cloud Management|Cloud services cr...|     1232|Spring 2023|       Spring|     2023|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1221|IST659|   M002|        20|      20|             3|Data Administrati...|Definition, devel...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                   false|                   false|                    true|                    true|\n",
      "|1221|IST659|   M001|        20|      20|             3|Data Administrati...|Definition, devel...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                   false|                   false|                    true|                    true|\n",
      "|1222|IST659|   M001|        24|      24|             3|Data Administrati...|Definition, devel...|     1222|Spring 2022|       Spring|     2022|         2021-2022|                   false|                   false|                    true|                    true|\n",
      "|1231|IST659|   M002|        20|      20|             3|Data Administrati...|Definition, devel...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1231|IST659|   M001|        20|      20|             3|Data Administrati...|Definition, devel...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1232|IST659|   M001|        20|      20|             3|Data Administrati...|Definition, devel...|     1232|Spring 2023|       Spring|     2023|         2022-2023|                   false|                   false|                    true|                    true|\n",
      "|1221|IST687|   M002|        21|      24|             3|Introduction to D...|Introduces inform...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                    true|                   false|                   false|                    true|\n",
      "|1221|IST687|   M001|        20|      20|             3|Introduction to D...|Introduces inform...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                    true|                   false|                   false|                    true|\n",
      "|1222|IST687|   M002|        20|      20|             3|Introduction to D...|Introduces inform...|     1222|Spring 2022|       Spring|     2022|         2021-2022|                    true|                   false|                   false|                    true|\n",
      "|1222|IST687|   M001|        18|      20|             3|Introduction to D...|Introduces inform...|     1222|Spring 2022|       Spring|     2022|         2021-2022|                    true|                   false|                   false|                    true|\n",
      "|1231|IST687|   M002|        20|      24|             3|Introduction to D...|Introduces inform...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                    true|                   false|                   false|                    true|\n",
      "|1231|IST687|   M001|        17|      20|             3|Introduction to D...|Introduces inform...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                    true|                   false|                   false|                    true|\n",
      "|1232|IST687|   M001|        19|      24|             3|Introduction to D...|Introduces inform...|     1232|Spring 2023|       Spring|     2023|         2022-2023|                    true|                   false|                   false|                    true|\n",
      "|1221|IST707|   M001|        28|      28|             3|Applied Machine L...|General overview ...|     1221|  Fall 2021|         Fall|     2021|         2021-2022|                    true|                   false|                   false|                    true|\n",
      "|1231|IST707|   M001|        24|      24|             3|Applied Machine L...|General overview ...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|                    true|                   false|                   false|                    true|\n",
      "+----+------+-------+----------+--------+--------------+--------------------+--------------------+---------+-----------+-------------+---------+------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7 flatten `course_is_elective_in_programs` and `course_is_required_in_programs` \n",
    "wide_sections.createOrReplaceTempView(\"wide_sections\")\n",
    "query = '''\n",
    "select \n",
    "    term,course,section,enrollment,capacity,\n",
    "    course_credits,course_title,course_description,\n",
    "    term_code,term_name,term_semester,term_year,term_academic_year, \n",
    "    array_contains(course_is_elective_in_programs,'IS') as course_is_elective_in_IS,\n",
    "    array_contains(course_is_elective_in_programs,'DS') as course_is_elective_in_DS,\n",
    "    array_contains(course_is_required_in_programs,'IS') as course_is_required_in_IS,\n",
    "    array_contains(course_is_required_in_programs,'DS') as course_is_required_in_DS\n",
    "\n",
    "from wide_sections\n",
    "'''\n",
    "wide_sections_flattened = spark.sql(query)\n",
    "wide_sections_flattened.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd3d88-efe9-4d0c-90ce-941ef6de84e2",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Load the data frame you created in question 7 into `elasticsearch`, under the index `sections`.  Demonstrate the data is in the index by querying back it with PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39d2c484-7857-4064-a60c-c1ec0004b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 291:====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+-----------------+--------------------+------------------------+------------------------+------------------------+------------------------+----------------+----------+-------+----+------------------+---------+-----------+-------------+---------+\n",
      "|capacity|course|course_credits|course_decription|  course_description|course_is_elective_in_DS|course_is_elective_in_IS|course_is_required_in_DS|course_is_required_in_IS|    course_title|enrollment|section|term|term_academic_year|term_code|  term_name|term_semester|term_year|\n",
      "+--------+------+--------------+-----------------+--------------------+------------------------+------------------------+------------------------+------------------------+----------------+----------+-------+----+------------------+---------+-----------+-------------+---------+\n",
      "|      28|IST615|             3|             null|Cloud services cr...|                   false|                   false|                    true|                    true|Cloud Management|        22|   M001|1221|         2021-2022|     1221|  Fall 2021|         Fall|     2021|\n",
      "|      24|IST615|             3|             null|Cloud services cr...|                   false|                   false|                    true|                    true|Cloud Management|        19|   M001|1222|         2021-2022|     1222|Spring 2022|       Spring|     2022|\n",
      "|      24|IST615|             3|             null|Cloud services cr...|                   false|                   false|                    true|                    true|Cloud Management|        21|   M001|1231|         2022-2023|     1231|  Fall 2022|         Fall|     2022|\n",
      "|      24|IST615|             3|             null|Cloud services cr...|                   false|                   false|                    true|                    true|Cloud Management|        20|   M002|1232|         2022-2023|     1232|Spring 2023|       Spring|     2023|\n",
      "|      28|IST615|             3|             null|Cloud services cr...|                   false|                   false|                    true|                    true|Cloud Management|        21|   M001|1232|         2022-2023|     1232|Spring 2023|       Spring|     2023|\n",
      "+--------+------+--------------+-----------------+--------------------+------------------------+------------------------+------------------------+------------------------+----------------+----------+-------+----+------------------+---------+-----------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#8 load wide_sections_flattened into elasticsearch\n",
    "wide_sections_flattened.write.mode(\"Overwrite\").format(\"es\").save(\"sections/_doc\")\n",
    "\n",
    "df = spark.read.format(\"es\").load(\"sections/_doc\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa738b4b-6970-46d4-b5dc-3c766f7fe64b",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Similar to question 4, prepare the `enrollments` for loading into `cassandra` and `elasticsearch` with Spark or Spark SQL. For this wide table we want to include the same reference data for `sections` but include the `student` attributes and the `program` data associated with the student. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce4ea5ef-282b-4aca-86c3-5401ef105088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------+-------+----------+-----+------------+------------+---------------+---------------+------------------------+------------+------------------------+------------+--------------+--------------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+--------------------+---------+-----------+-------------+---------+------------------+\n",
      "|term|course_enrollment|course|section|student_id|grade|grade_points|student_name|student_program|program_credits|program_elective_courses|program_name|program_required_courses|program_type|course_credits|        course_title|   course_decription|course_is_elective_in_programs|course_is_required_in_programs|course_prerequisites|course_key_assignments|  course_description|term_code|  term_name|term_semester|term_year|term_academic_year|\n",
      "+----+-----------------+------+-------+----------+-----+------------+------------+---------------+---------------+------------------------+------------+------------------------+------------+--------------+--------------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+--------------------+---------+-----------+-------------+---------+------------------+\n",
      "|1231|               12|IST615|   M001|artiechoke|    A|         4.0| Artie Choke|             DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|             3|    Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|Cloud services cr...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|\n",
      "|1231|               18|IST659|   M002|artiechoke|    A|         4.0| Artie Choke|             DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|             3|Data Administrati...|Definition, devel...|                            []|                      [IS, DS]|                  []|             [project]|Definition, devel...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|\n",
      "|1231|                6|IST687|   M002|artiechoke|    A|         4.0| Artie Choke|             DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|             3|Introduction to D...|Introduces inform...|                          [IS]|                          [DS]|                  []|       [project, exam]|Introduces inform...|     1231|  Fall 2022|         Fall|     2022|         2022-2023|\n",
      "|1232|               21|IST621|   M001|artiechoke|    A|         4.0| Artie Choke|             DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|             3|Information Manag...|Information and t...|                            []|                          [IS]|                  []|               [paper]|Information and t...|     1232|Spring 2023|       Spring|     2023|         2022-2023|\n",
      "|1222|               18|IST615|   M001|peteterpan|    A|         4.0| Pete Terpan|             DS|             34|        [IST769, IST714]|Data Science|    [IST659, IST615, ...|     Masters|             3|    Cloud Management|Cloud services cr...|                            []|                      [IS, DS]|                  []|      [project, paper]|Cloud services cr...|     1222|Spring 2022|       Spring|     2022|         2021-2022|\n",
      "+----+-----------------+------+-------+----------+-----+------------+------------+---------------+---------------+------------------------+------------+------------------------+------------+--------------+--------------------+--------------------+------------------------------+------------------------------+--------------------+----------------------+--------------------+---------+-----------+-------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- term: string (nullable = true)\n",
      " |-- course_enrollment: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- student_id: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- grade_points: string (nullable = true)\n",
      " |-- student_name: string (nullable = true)\n",
      " |-- student_program: string (nullable = true)\n",
      " |-- program_credits: integer (nullable = true)\n",
      " |-- program_elective_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- program_name: string (nullable = true)\n",
      " |-- program_required_courses: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- program_type: string (nullable = true)\n",
      " |-- course_credits: integer (nullable = true)\n",
      " |-- course_title: string (nullable = true)\n",
      " |-- course_decription: string (nullable = true)\n",
      " |-- course_is_elective_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_is_required_in_programs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_prerequisites: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_key_assignments: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- course_description: string (nullable = true)\n",
      " |-- term_code: string (nullable = true)\n",
      " |-- term_name: string (nullable = true)\n",
      " |-- term_semester: string (nullable = true)\n",
      " |-- term_year: integer (nullable = true)\n",
      " |-- term_academic_year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9 create wide_enrollments\n",
    "\n",
    "terms.createOrReplaceTempView(\"terms\")\n",
    "courses.createOrReplaceTempView(\"courses\")\n",
    "students.createOrReplaceTempView(\"students\")\n",
    "enrollments.createOrReplaceTempView(\"enrollments\")\n",
    "programs.createOrReplaceTempView(\"programs\")\n",
    "\n",
    "query = '''\n",
    "    select \n",
    "        e.*,\n",
    "        s.name as student_name,\n",
    "        s.program as student_program,\n",
    "        p.credits as program_credits,\n",
    "        p.elective_courses as program_elective_courses,\n",
    "        p.name as program_name, \n",
    "        p.required_courses as program_required_courses,\n",
    "        p.type as program_type,\n",
    "        c.credits as course_credits,\n",
    "        c.name as course_title,\n",
    "        c.description as course_decription,\n",
    "        c.elective_in_programs as course_is_elective_in_programs,\n",
    "        c.required_in_programs as course_is_required_in_programs,\n",
    "        c.prerequisites as course_prerequisites,\n",
    "        c.key_assignments as course_key_assignments,\n",
    "        c.description as course_description,\n",
    "        t.code as term_code,\n",
    "        t.name as term_name,\n",
    "        t.semester as term_semester,\n",
    "        t.year as term_year,\n",
    "        t.academic_year as term_academic_year        \n",
    "    from enrollments e\n",
    "        join terms t on e.term = t._id\n",
    "        join courses c on e.course = c._id\n",
    "        join students s on s._id = e.student_id\n",
    "        join programs p on p._id = s.program\n",
    "'''\n",
    "wide_enrollments = spark.sql(query)\n",
    "wide_enrollments.show(5)\n",
    "wide_enrollments.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae284c8-096a-4987-98cf-0800cedced12",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Load the data frame you created in question 8 into `elasticsearch`, under the index `enrollments`. This time, just Omit all array types to make the problem simpler (`elective_courses`, `key_assignments`, `course_prerequisites`, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a42dedc-62c4-4b83-b431-2a3474834901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 336:===================================================> (196 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-----------------+--------------------+-----------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+-----+------------+---------------+------------------------+------------+------------------------+------------+-------+----------+------------+---------------+----+------------------+---------+-----------+-------------+---------+\n",
      "|course|course_credits|course_decription|  course_description|course_enrollment|course_is_elective_in_programs|course_is_required_in_programs|course_key_assignments|course_prerequisites|        course_title|grade|grade_points|program_credits|program_elective_courses|program_name|program_required_courses|program_type|section|student_id|student_name|student_program|term|term_academic_year|term_code|  term_name|term_semester|term_year|\n",
      "+------+--------------+-----------------+--------------------+-----------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+-----+------------+---------------+------------------------+------------+------------------------+------------+-------+----------+------------+---------------+----+------------------+---------+-----------+-------------+---------+\n",
      "|IST615|             3|             null|Cloud services cr...|               12|                          null|                          null|                  null|                null|    Cloud Management|    A|         4.0|             34|                    null|Data Science|                    null|     Masters|   M001|artiechoke| Artie Choke|             DS|1231|         2022-2023|     null|  Fall 2022|         Fall|     2022|\n",
      "|IST659|             3|             null|Definition, devel...|               18|                          null|                          null|                  null|                null|Data Administrati...|    A|         4.0|             34|                    null|Data Science|                    null|     Masters|   M002|artiechoke| Artie Choke|             DS|1231|         2022-2023|     null|  Fall 2022|         Fall|     2022|\n",
      "|IST687|             3|             null|Introduces inform...|                6|                          null|                          null|                  null|                null|Introduction to D...|    A|         4.0|             34|                    null|Data Science|                    null|     Masters|   M002|artiechoke| Artie Choke|             DS|1231|         2022-2023|     null|  Fall 2022|         Fall|     2022|\n",
      "|IST621|             3|             null|Information and t...|               21|                          null|                          null|                  null|                null|Information Manag...|    A|         4.0|             34|                    null|Data Science|                    null|     Masters|   M001|artiechoke| Artie Choke|             DS|1232|         2022-2023|     null|Spring 2023|       Spring|     2023|\n",
      "|IST615|             3|             null|Cloud services cr...|               18|                          null|                          null|                  null|                null|    Cloud Management|    A|         4.0|             34|                    null|Data Science|                    null|     Masters|   M001|peteterpan| Pete Terpan|             DS|1222|         2021-2022|     null|Spring 2022|       Spring|     2022|\n",
      "+------+--------------+-----------------+--------------------+-----------------+------------------------------+------------------------------+----------------------+--------------------+--------------------+-----+------------+---------------+------------------------+------------+------------------------+------------+-------+----------+------------+---------------+----+------------------+---------+-----------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#10 wide_enrollments to elastic search\n",
    "wide_enrollments.createOrReplaceTempView(\"wide_enrollments\")\n",
    "query = '''\n",
    "select   term,\n",
    "  course_enrollment,\n",
    "  course,\n",
    "  section,\n",
    "  student_id,\n",
    "  grade,\n",
    "  grade_points,\n",
    "  student_name,\n",
    "  student_program,\n",
    "  program_credits,\n",
    "  program_name,\n",
    "  program_type,\n",
    "  course_credits,\n",
    "  course_title,\n",
    "  course_description,\n",
    "  term_name,\n",
    "  term_semester,\n",
    "  term_year,\n",
    "  term_academic_year\n",
    "from wide_enrollments\n",
    "'''\n",
    "\n",
    "spark.sql(query).write.mode(\"Overwrite\").format(\"es\").save(\"enrollments/_doc\")\n",
    "\n",
    "df = spark.read.format(\"es\").load(\"enrollments/_doc\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baf832-3a14-45c9-9594-d607439b845a",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bd7a903e-789b-4b01-8501-6041190b50c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'emptyDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50/324424345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memptyDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'emptyDataFrame'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6910199-edde-418d-b6fa-06c5d810ce3d",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Load the `courses` and `program` data into `neo4j` as nodes. Exclude the `requirements`, `electives` and `prerequisites` from the node attributes. Demonstrate the data in `neo4j` by querying back it using one or more Cypher queries. NOTE: the Neo4J `name` attribute is what will display on the node bubbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32387c55-0142-4838-8300-498839f3ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12a reset neo4j database if required\n",
    "cipher_ql = \"match (x) detach delete x;\"\n",
    "courses.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71eeb25c-fa18-4702-9595-34f443aca315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12a load courses into Neo4j\n",
    "cipher_ql = '''MERGE (c:Courses { \n",
    "    name : event.code, credits : event.credits, \n",
    "    title: event.name, description: event.description, \n",
    "    key_assignments: event.key_assignments\n",
    "    }\n",
    ")\n",
    "'''\n",
    "courses.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69aa723b-5479-4232-aca3-0197e199cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12b load programs into neo4j\n",
    "cipher_ql = '''MERGE (p:Programs { \n",
    "    code : event.code, name : event.name, \n",
    "    type: event.type, credits: event.credits\n",
    "    }\n",
    ")\n",
    "'''\n",
    "programs.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5508275-5202-43f5-8adf-773dc22fc681",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "Load the `requirements` and `electives` data into `neo4j` as relationships to the nodes you created in Question 12. Use the `program` data to form the `required` and `elective` course relationships. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f782d89-fa86-4c79-b1f0-baf383c47100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12a program course requirements\n",
    "query = 'select code, explode(required_courses) as required_course from programs'\n",
    "cipher_ql = '''\n",
    "    MATCH (p:Programs {code: event.code}), (c:Courses {name: event.required_course})\n",
    "    MERGE(c)-[:REQUIRED_IN]->(p);\n",
    "'''\n",
    "spark.sql(query).write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9abc97bf-a75a-48d9-902a-aae259211e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12b program course electives\n",
    "query = 'select code, explode(elective_courses) as elective_course from programs'\n",
    "cipher_ql = '''\n",
    "    MATCH (p:Programs {code: event.code}), (c:Courses {name: event.elective_course})\n",
    "    MERGE(c)-[:ELECTIVE_IN]->(p);\n",
    "'''\n",
    "spark.sql(query).write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad62a7-505a-4bb8-a2bd-3756cf6719d5",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Load the `prerequisites` into `neo4j` as relationships to the `course` nodes you created in Question 12. Demonstrate the relationships in `neo4j` are present by querying back it using one or more Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b9e586b-c5be-4908-bc31-26ab6ef5ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select code as course, explode(prerequisites) as prerequisite_course from courses'\n",
    "cipher_ql = '''\n",
    "    MATCH (c:Courses {name: event.course}), (p:Courses {name: event.prerequisite_course})\n",
    "    MERGE(c)-[:PREREQUISITE]->(p);\n",
    "'''\n",
    "spark.sql(query).write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4d61d-5076-4d6e-9f54-03e437d18333",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Write a Cypher query to display courses which are required by both the `IS` and `DS` programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252e315-eaba-47ee-9f8e-11fc43529c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 Cypher query\n",
    "\n",
    "Match (p2: Programs {code: 'DS'})<-[:REQUIRED_IN]-\n",
    "    (c:Courses)-[:REQUIRED_IN]->(p1:Programs {code: 'IS'})\n",
    "return p2,c,p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe6590-97e2-477f-b860-7ffd5fe63640",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "\n",
    "Write a Cypher query to retrieve the `course code`, `course title`, and the count of programs the course is a requirement in. Write as a Cypher query but retrieve the  output as a Spark Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b68985d-c57c-42b3-87a5-4b9c4b6114f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------+\n",
      "|c.name|             c.title|program_count|\n",
      "+------+--------------------+-------------+\n",
      "|IST621|Information Manag...|            2|\n",
      "|IST615|    Cloud Management|            3|\n",
      "|IST659|Data Administrati...|            3|\n",
      "|IST707|Applied Machine L...|            2|\n",
      "|IST718|  Big Data Analytics|            2|\n",
      "|IST687|Introduction to D...|            2|\n",
      "|IST769|Advanced Big Data...|            1|\n",
      "|IST722|    Data Warehousing|            1|\n",
      "|IST714|  Cloud Architecture|            1|\n",
      "+------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#16 Cypher to spark\n",
    "\n",
    "cipher_ql = '''\n",
    "MATCH (c:Courses)-[:REQUIRED_IN]->(p:Programs) \n",
    "WITH c, count(p) as program_count \n",
    "RETURN c.name, c.title, program_count\n",
    "'''\n",
    "df = spark.read.format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225c3eb-b6e2-4008-8d7e-e9d2630de4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a325023-16c4-42ee-bdb1-5fb24079ad77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbaced0-7364-4aa2-9138-e9f45ee25fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07486e-3719-4f13-80e2-d675551ae1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b32fb-f5d6-4a14-92f1-81261595ddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633dd843-c6a1-4c90-9903-fdd130d0c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
